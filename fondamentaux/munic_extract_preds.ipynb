{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook extracts and formats 4 predictor variables (number of working inhabitants, number of college graduates, number of youth (18-24) and number of immigrants) by Parisian district over the period 2006-2016 (last available year). These data come from Insee's IRIS database, which collects several hundreds of variables at the sub-city level. \n",
    "\n",
    "We selected four variables that we believe have a strong influence (potentially causal) on the outcome of elections in each district of Paris. Our assumption may be wrong, but it will be easy to see that once we put the data into the model -- it won't run or will tell us that these variables are not correlated with the outcome. The model will use these predictors to try and predict election results in each district, but we'll do that in another notebook. \n",
    "\n",
    "Let's start with some import statements and a handy function to extract predictors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext watermark\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "repos = [\"activite_residents\", \"diplomes_formation\", \"population\", \"population\"]\n",
    "var_codes = [\"C_ACTOCC1564\", \"P_NSCOL15P_SUP\", \"P_POP1824\", \"P_POP_IMM\"]\n",
    "var_names = [\"actifs_occupes\", \"college_grad\", \"youth\", \"immigration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_predictor(repo: str, var_code: str, var_name: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Gets all files in the given repo, selects wanted predictor variable, \n",
    "    restricts to Paris, extracts the district numbers, aggregates predictor by district,\n",
    "    and then returns formatted time series\n",
    "    \"\"\"\n",
    "    basepath = Path(f\"../../../Downloads/db_iris_all/{repo}/\")\n",
    "    files_in_path = basepath.glob(\"*.xls\")\n",
    "    print(f\"Began extracting {var_name} predictor from {repo} repo...\\n\")\n",
    "\n",
    "    # load and concat files (heavy):\n",
    "    preds = pd.DataFrame()\n",
    "    for file in files_in_path:\n",
    "        df = pd.read_excel(\n",
    "            file,\n",
    "            header=5,\n",
    "            sheet_name=\"IRIS\",\n",
    "            usecols=[\"DEP\", \"LIBCOM\", f\"{var_code[:1]}{file.stem[-2:]}{var_code[1:]}\"],\n",
    "            dtype={\"DEP\": \"category\", \"LIBCOM\": \"category\"},\n",
    "            nrows=40_500,\n",
    "        )\n",
    "        df = df[df.DEP == \"75\"].reset_index(drop=True).drop(\"DEP\", axis=1)\n",
    "        preds = pd.concat([preds, df], axis=1)\n",
    "\n",
    "    # drop duplicated column values:\n",
    "    preds = preds.T.drop_duplicates().T\n",
    "    # drop duplicated column names:\n",
    "    preds = preds.loc[:, ~preds.columns.duplicated()]\n",
    "\n",
    "    # extract district number:\n",
    "    preds[\"LIBCOM\"] = preds.LIBCOM.str.extract(\"(\\d+)\").astype(int)\n",
    "    preds = preds.rename(columns={\"LIBCOM\": \"arrondissement\"})\n",
    "\n",
    "    # aggregate by district and prettify columns:\n",
    "    preds = preds.groupby(\"arrondissement\").sum()\n",
    "    preds.columns = preds.columns.str[1:3].astype(int) + 2000\n",
    "    preds.columns.name = \"year\"\n",
    "    preds = preds.sort_index(axis=1)\n",
    "    preds = preds.stack()\n",
    "    preds.name = var_name\n",
    "\n",
    "    print(f\"Finished extracting and aggregating {var_name} predictor.\\n\")\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw excel files where the data live are very heavy, so this function will take some time to run -- but it will be worth it. Indeed, it will go and load the files where each predictor is, for  each year on record, do some formatting and restricting and then return a dataframe with the proper time series. Let's run it and go get a cup of coffee:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Began extracting actifs_occupes predictor from activite_residents repo\n",
      "\n",
      "Finished extracting and aggregating actifs_occupes predictor\n",
      "\n",
      "Began extracting college_grad predictor from diplomes_formation repo\n",
      "\n",
      "Finished extracting and aggregating college_grad predictor\n",
      "\n",
      "Began extracting youth predictor from population repo\n",
      "\n",
      "Finished extracting and aggregating youth predictor\n",
      "\n",
      "Began extracting immigration predictor from population repo\n",
      "\n",
      "Finished extracting and aggregating immigration predictor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictors = []\n",
    "for r, c, n in zip(repos, var_codes, var_names):\n",
    "    predictors.append(extract_predictor(r, c, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>actifs_occupes</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>youth</th>\n",
       "      <th>immigration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrondissement</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>2006</th>\n",
       "      <td>9485.059228</td>\n",
       "      <td>6453.630949</td>\n",
       "      <td>1874.672223</td>\n",
       "      <td>3148.134542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>9546.148694</td>\n",
       "      <td>6731.105539</td>\n",
       "      <td>1866.646378</td>\n",
       "      <td>3227.921219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>9469.633224</td>\n",
       "      <td>6770.997547</td>\n",
       "      <td>1816.180756</td>\n",
       "      <td>3121.358408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>9665.691628</td>\n",
       "      <td>6994.804860</td>\n",
       "      <td>1842.097989</td>\n",
       "      <td>3121.406343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>9558.180760</td>\n",
       "      <td>7009.239728</td>\n",
       "      <td>1779.033595</td>\n",
       "      <td>3021.113668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20</th>\n",
       "      <th>2012</th>\n",
       "      <td>91753.677270</td>\n",
       "      <td>44244.946169</td>\n",
       "      <td>18234.641207</td>\n",
       "      <td>43045.904247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>90488.610079</td>\n",
       "      <td>63058.398038</td>\n",
       "      <td>18156.671990</td>\n",
       "      <td>42888.160363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>90469.181326</td>\n",
       "      <td>66282.764695</td>\n",
       "      <td>18133.119561</td>\n",
       "      <td>42123.803538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>90370.240523</td>\n",
       "      <td>68786.240273</td>\n",
       "      <td>17977.773858</td>\n",
       "      <td>41633.325845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>90874.227479</td>\n",
       "      <td>71851.173023</td>\n",
       "      <td>17537.759874</td>\n",
       "      <td>41180.244725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     actifs_occupes  college_grad         youth   immigration\n",
       "arrondissement year                                                          \n",
       "1              2006     9485.059228   6453.630949   1874.672223   3148.134542\n",
       "               2007     9546.148694   6731.105539   1866.646378   3227.921219\n",
       "               2008     9469.633224   6770.997547   1816.180756   3121.358408\n",
       "               2009     9665.691628   6994.804860   1842.097989   3121.406343\n",
       "               2010     9558.180760   7009.239728   1779.033595   3021.113668\n",
       "...                             ...           ...           ...           ...\n",
       "20             2012    91753.677270  44244.946169  18234.641207  43045.904247\n",
       "               2013    90488.610079  63058.398038  18156.671990  42888.160363\n",
       "               2014    90469.181326  66282.764695  18133.119561  42123.803538\n",
       "               2015    90370.240523  68786.240273  17977.773858  41633.325845\n",
       "               2016    90874.227479  71851.173023  17537.759874  41180.244725\n",
       "\n",
       "[220 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = pd.concat(predictors, axis=1)\n",
    "predictors.to_csv(\"data/predictors_by_district.csv\")\n",
    "predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Had a nice coffee? As you can see, we now have the predictors ready to match with past election results, and then to give to the model! Let's do that in another notebook.\n",
    "\n",
    "## Interpolation (Pm-Prophet, sk-learn)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fund",
   "language": "python",
   "name": "fund"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
